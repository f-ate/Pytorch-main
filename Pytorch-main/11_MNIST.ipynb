{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905a605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d063bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa249c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d5f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab5d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df122d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aarav/anaconda3/envs/pract/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='data',train = True,\n",
    "                                          transform = transforms.ToTensor(),\n",
    "                                          download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90222b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='data',train=False,\n",
    "                                         transform = transforms.ToTensor(),\n",
    "                                         download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52715a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299b436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20cc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db116f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13a4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e96b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples ,labels = examples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec97b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9dc577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5331db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(samples[i][0],cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892acb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6253ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size,hidden_size,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ecb9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (l1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (l2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414f4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss func^ & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cfbd231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/20, step 100/600,loss = 0.4868\n",
      "epoch 1/20, step 200/600,loss = 0.2395\n",
      "epoch 1/20, step 300/600,loss = 0.4358\n",
      "epoch 1/20, step 400/600,loss = 0.2317\n",
      "epoch 1/20, step 500/600,loss = 0.1894\n",
      "epoch 1/20, step 600/600,loss = 0.3975\n",
      "epoch 2/20, step 100/600,loss = 0.2852\n",
      "epoch 2/20, step 200/600,loss = 0.1905\n",
      "epoch 2/20, step 300/600,loss = 0.1997\n",
      "epoch 2/20, step 400/600,loss = 0.2918\n",
      "epoch 2/20, step 500/600,loss = 0.2603\n",
      "epoch 2/20, step 600/600,loss = 0.2387\n",
      "epoch 3/20, step 100/600,loss = 0.1352\n",
      "epoch 3/20, step 200/600,loss = 0.1576\n",
      "epoch 3/20, step 300/600,loss = 0.0898\n",
      "epoch 3/20, step 400/600,loss = 0.1905\n",
      "epoch 3/20, step 500/600,loss = 0.1387\n",
      "epoch 3/20, step 600/600,loss = 0.1605\n",
      "epoch 4/20, step 100/600,loss = 0.0743\n",
      "epoch 4/20, step 200/600,loss = 0.0735\n",
      "epoch 4/20, step 300/600,loss = 0.1230\n",
      "epoch 4/20, step 400/600,loss = 0.1221\n",
      "epoch 4/20, step 500/600,loss = 0.1078\n",
      "epoch 4/20, step 600/600,loss = 0.2019\n",
      "epoch 5/20, step 100/600,loss = 0.0969\n",
      "epoch 5/20, step 200/600,loss = 0.2038\n",
      "epoch 5/20, step 300/600,loss = 0.0477\n",
      "epoch 5/20, step 400/600,loss = 0.0984\n",
      "epoch 5/20, step 500/600,loss = 0.1025\n",
      "epoch 5/20, step 600/600,loss = 0.0913\n",
      "epoch 6/20, step 100/600,loss = 0.0615\n",
      "epoch 6/20, step 200/600,loss = 0.0587\n",
      "epoch 6/20, step 300/600,loss = 0.0600\n",
      "epoch 6/20, step 400/600,loss = 0.0857\n",
      "epoch 6/20, step 500/600,loss = 0.0748\n",
      "epoch 6/20, step 600/600,loss = 0.1176\n",
      "epoch 7/20, step 100/600,loss = 0.0351\n",
      "epoch 7/20, step 200/600,loss = 0.0478\n",
      "epoch 7/20, step 300/600,loss = 0.0344\n",
      "epoch 7/20, step 400/600,loss = 0.0473\n",
      "epoch 7/20, step 500/600,loss = 0.0461\n",
      "epoch 7/20, step 600/600,loss = 0.0415\n",
      "epoch 8/20, step 100/600,loss = 0.0178\n",
      "epoch 8/20, step 200/600,loss = 0.0254\n",
      "epoch 8/20, step 300/600,loss = 0.0292\n",
      "epoch 8/20, step 400/600,loss = 0.0560\n",
      "epoch 8/20, step 500/600,loss = 0.0730\n",
      "epoch 8/20, step 600/600,loss = 0.0593\n",
      "epoch 9/20, step 100/600,loss = 0.0208\n",
      "epoch 9/20, step 200/600,loss = 0.0437\n",
      "epoch 9/20, step 300/600,loss = 0.0352\n",
      "epoch 9/20, step 400/600,loss = 0.0176\n",
      "epoch 9/20, step 500/600,loss = 0.0381\n",
      "epoch 9/20, step 600/600,loss = 0.0991\n",
      "epoch 10/20, step 100/600,loss = 0.0330\n",
      "epoch 10/20, step 200/600,loss = 0.0148\n",
      "epoch 10/20, step 300/600,loss = 0.0115\n",
      "epoch 10/20, step 400/600,loss = 0.0141\n",
      "epoch 10/20, step 500/600,loss = 0.0232\n",
      "epoch 10/20, step 600/600,loss = 0.0235\n",
      "epoch 11/20, step 100/600,loss = 0.0621\n",
      "epoch 11/20, step 200/600,loss = 0.0442\n",
      "epoch 11/20, step 300/600,loss = 0.0182\n",
      "epoch 11/20, step 400/600,loss = 0.0225\n",
      "epoch 11/20, step 500/600,loss = 0.0170\n",
      "epoch 11/20, step 600/600,loss = 0.0406\n",
      "epoch 12/20, step 100/600,loss = 0.0435\n",
      "epoch 12/20, step 200/600,loss = 0.0244\n",
      "epoch 12/20, step 300/600,loss = 0.0268\n",
      "epoch 12/20, step 400/600,loss = 0.0279\n",
      "epoch 12/20, step 500/600,loss = 0.0821\n",
      "epoch 12/20, step 600/600,loss = 0.0211\n",
      "epoch 13/20, step 100/600,loss = 0.0331\n",
      "epoch 13/20, step 200/600,loss = 0.0296\n",
      "epoch 13/20, step 300/600,loss = 0.0052\n",
      "epoch 13/20, step 400/600,loss = 0.0562\n",
      "epoch 13/20, step 500/600,loss = 0.0331\n",
      "epoch 13/20, step 600/600,loss = 0.0107\n",
      "epoch 14/20, step 100/600,loss = 0.0111\n",
      "epoch 14/20, step 200/600,loss = 0.0363\n",
      "epoch 14/20, step 300/600,loss = 0.0141\n",
      "epoch 14/20, step 400/600,loss = 0.0064\n",
      "epoch 14/20, step 500/600,loss = 0.0234\n",
      "epoch 14/20, step 600/600,loss = 0.0052\n",
      "epoch 15/20, step 100/600,loss = 0.0087\n",
      "epoch 15/20, step 200/600,loss = 0.0209\n",
      "epoch 15/20, step 300/600,loss = 0.0359\n",
      "epoch 15/20, step 400/600,loss = 0.0372\n",
      "epoch 15/20, step 500/600,loss = 0.0194\n",
      "epoch 15/20, step 600/600,loss = 0.0072\n",
      "epoch 16/20, step 100/600,loss = 0.0111\n",
      "epoch 16/20, step 200/600,loss = 0.0259\n",
      "epoch 16/20, step 300/600,loss = 0.0134\n",
      "epoch 16/20, step 400/600,loss = 0.0074\n",
      "epoch 16/20, step 500/600,loss = 0.0092\n",
      "epoch 16/20, step 600/600,loss = 0.0165\n",
      "epoch 17/20, step 100/600,loss = 0.0237\n",
      "epoch 17/20, step 200/600,loss = 0.0137\n",
      "epoch 17/20, step 300/600,loss = 0.0048\n",
      "epoch 17/20, step 400/600,loss = 0.0127\n",
      "epoch 17/20, step 500/600,loss = 0.0095\n",
      "epoch 17/20, step 600/600,loss = 0.0051\n",
      "epoch 18/20, step 100/600,loss = 0.0042\n",
      "epoch 18/20, step 200/600,loss = 0.0071\n",
      "epoch 18/20, step 300/600,loss = 0.0065\n",
      "epoch 18/20, step 400/600,loss = 0.0038\n",
      "epoch 18/20, step 500/600,loss = 0.0095\n",
      "epoch 18/20, step 600/600,loss = 0.0503\n",
      "epoch 19/20, step 100/600,loss = 0.0141\n",
      "epoch 19/20, step 200/600,loss = 0.0103\n",
      "epoch 19/20, step 300/600,loss = 0.0087\n",
      "epoch 19/20, step 400/600,loss = 0.0121\n",
      "epoch 19/20, step 500/600,loss = 0.0045\n",
      "epoch 19/20, step 600/600,loss = 0.0034\n",
      "epoch 20/20, step 100/600,loss = 0.0083\n",
      "epoch 20/20, step 200/600,loss = 0.0037\n",
      "epoch 20/20, step 300/600,loss = 0.0071\n",
      "epoch 20/20, step 400/600,loss = 0.0055\n",
      "epoch 20/20, step 500/600,loss = 0.0153\n",
      "epoch 20/20, step 600/600,loss = 0.0079\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        #backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps},loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e9ca28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6daec39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "    _, predictions = torch.max(outputs,1)\n",
    "    n_samples += labels.shape[0]\n",
    "    n_correct += (predictions ==  labels).sum().item()\n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    print(f\"accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5da10300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "602dd15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba8a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
